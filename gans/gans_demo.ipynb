{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gans_demo",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keNfFHvidCRH",
        "colab_type": "text"
      },
      "source": [
        "# **Dependencies**\n",
        "\n",
        "This is easier to run inside Google Colab, but it can also be ran in your own machine. In that case, a GPU is recommended, otherwise this will take ages to run.\n",
        "\n",
        "Depending on the case, run the appropriate cell bellow to install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wVUud-O4xsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you are NOT in Google Colab, run this:\n",
        "\n",
        "!pip install PyDrive tensorflow matplotlib numpy scikit-image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dniv41kS94UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you are insode Google Colab, run this instead\n",
        "\n",
        "!pip install PyDrive\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-4VPHaLZ4uSS",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "# stuff used to get the file from google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLtnPPGe4-3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# which version of tensorflow are we using? and are we using a gpu?\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "\n",
        "tf_device = tf.test.gpu_device_name()\n",
        "if 'GPU' not in tf_device:\n",
        "    print('GPU not found :(')\n",
        "else:\n",
        "    print('Using GPU: {}'.format(tf_device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgdxjI2tdpjp",
        "colab_type": "text"
      },
      "source": [
        "# **Getting the data**\n",
        "\n",
        "To run this example, we need to get a file which contains the example images. This file can be downloaded from:\n",
        "https://drive.google.com/open?id=1JWwYHf-mTtq1JUWMfrqFNtjm4yOvz1bc\n",
        "\n",
        "If you are running this in yuor machine, download the file and place it in the same folder as the notebook. And don't run this cell.\n",
        "\n",
        "If you are running this inside Google Colab, run this cell and follow the instructions to get the file into the Colab runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM2iDhoa7HiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if we are running inside Google Colab, automatically get the images file from\n",
        "# Google Drive:\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1JWwYHf-mTtq1JUWMfrqFNtjm4yOvz1bc'}) \n",
        "downloaded.GetContentFile('profes_images_array.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q30rQzNGed4O",
        "colab_type": "text"
      },
      "source": [
        "# **Reading the data**\n",
        "\n",
        "The pickle file contains images, that are 32x32 pixels, with 3 color channels (red, green, blue):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XGvzBZ7_wlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_images = np.load('profes_images_array.pkl')\n",
        "real_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xD0g-YZKe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample pixel\n",
        "real_images[500][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbdBpVDdBgHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(images, sample_size):\n",
        "    \"\"\"\n",
        "    Make a random sample of a set of images.\n",
        "    \"\"\"\n",
        "    return images[np.random.randint(len(images), size=sample_size)]\n",
        "\n",
        "\n",
        "def show_images_grid(images, normalized=True, grid_size=3, fig_size=10, \n",
        "                     file_name=None):\n",
        "    \"\"\"\n",
        "    Given a set of images, show them together and optionally save the \n",
        "    collage to a file.\n",
        "    \"\"\"\n",
        "    assert len(images) <= (grid_size ** 2)\n",
        "    fig = plt.figure(figsize=(fig_size, fig_size))\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(grid_size, grid_size, i+1)\n",
        "        plt.axis('off')\n",
        "        if normalized:\n",
        "            plt.imshow((image / 2) + 0.5)\n",
        "        else:\n",
        "            plt.imshow(image)\n",
        "\n",
        "    if file_name is not None:\n",
        "        plt.savefig(file_name)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbBcVVIYcsb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_images_grid(sample(real_images, 9), normalized=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-EBbshJ4_JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the images so the numbers go between -1 and 1\n",
        "processed_real_images = ((real_images - 127.5) / 127.5)\n",
        "\n",
        "# resize the images, so we can train faster during the demo\n",
        "processed_real_images = np.array([resize(image, (16, 16, 3))\n",
        "                                  for image in processed_real_images])\n",
        "# and use a smaller data type\n",
        "processed_real_images = processed_real_images.astype('float32')\n",
        "\n",
        "processed_real_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBvGIO_BVUNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample normalized pixel (same pixel we saw before)\n",
        "processed_real_images[500][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIPcJBTMBhh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_images_grid(sample(processed_real_images, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGhK1jTlZZr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a TF dataset, increasing the number of images (repeating them), and \n",
        "# grouping them in batches for easier training\n",
        "BATCH_SIZE = 256\n",
        "real_images_dataset = tf.data.Dataset.from_tensor_slices(processed_real_images)\\\n",
        "                                     .shuffle(100000)\\\n",
        "                                     .batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evQeGUlqfP3f",
        "colab_type": "text"
      },
      "source": [
        "# **The neural networks**\n",
        "\n",
        "Here we create the two networks, that will be trained together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrPrNzO3-fV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the network that will generate images\n",
        "# - it will receive random noise as input\n",
        "# - the ouput will be a normalized image with shape 32x32x3\n",
        "\n",
        "generator = tf.keras.Sequential([\n",
        "    layers.Dense(4 * 4 * 256, use_bias=False, input_shape=(100,)),\n",
        "    layers.LeakyReLU(),\n",
        "\n",
        "    layers.Reshape((4, 4, 256)),\n",
        "\n",
        "    layers.Conv2DTranspose(128, (4, 4), strides=1, padding='same',\n",
        "                           use_bias=False),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(),\n",
        "\n",
        "    layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same',\n",
        "                           use_bias=False),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(),\n",
        "\n",
        "    layers.Conv2DTranspose(3, (4, 4), strides=2, padding='same', use_bias=False,\n",
        "                           activation='tanh'),\n",
        "])\n",
        "\n",
        "assert generator.output_shape == (None, 16, 16, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dba32Mxt_ISt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets test it!\n",
        "# give random noise to the generator, and see what images it produces!\n",
        "# (of course, it's still quite dumb)\n",
        "\n",
        "noise = tf.random.normal([9, 100])\n",
        "generated_images = generator(noise, training=False)\n",
        "\n",
        "show_images_grid(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYTSMpOrFxgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the network that will try to guess which image is real and which image\n",
        "# is generated (fake)\n",
        "# - it will receive a normalized image as input (32x32x3)\n",
        "# - the ouput is a single number, that we expect it to say if the image is fake\n",
        "#   (negative) or real (positive).\n",
        "\n",
        "discriminator = tf.keras.Sequential([\n",
        "    layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                    input_shape=[16, 16, 3]),\n",
        "    layers.LeakyReLU(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
        "    layers.LeakyReLU(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
        "    layers.LeakyReLU(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32),\n",
        "    layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlytI8bdIxaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets test it!\n",
        "# give it a few fake images, and see what it says about them\n",
        "# (of course, it's still quite dumb)\n",
        "\n",
        "discriminator(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYbUKO7MMFL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# give it a few real images, and see what it says about them\n",
        "# (still quite dumb)\n",
        "\n",
        "discriminator(sample(processed_real_images, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnO72LBgz--",
        "colab_type": "text"
      },
      "source": [
        "# **How will the networks learn**\n",
        "\n",
        "To train these networks, we need some kind of loss (\"error\") function that describes how much did they fail in their tasks. This will be used during training, to help them learn to do their work better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt0VYNDCJLMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # binary cross entropy is a function that tells lets us measure errors between\n",
        " # sets of numbers that go between 0 and 1\n",
        "\n",
        " # TODO sacar from_logits, agregar activacion a la salida de discriminator\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpXTML6YKDi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating the discriminator net:\n",
        "# we gave the net 2 sets of images: reals and fakes. We expect it to answer \"1\"\n",
        "# in all the real images, and \"0\" in all the fake images\n",
        "# the \"error\" of the discriminator net is then, how different its predictions\n",
        "# have been, compared to those expected outputs\n",
        "\n",
        "def discriminator_loss(real_images_predictions, fake_images_predictions):\n",
        "    # cross entropy between values predicted for real images, and all 1s\n",
        "    real_loss = cross_entropy(tf.ones_like(real_images_predictions), \n",
        "                              real_images_predictions)\n",
        "    # cross entropy between values predicted for fake images, and all 0s\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_images_predictions), \n",
        "                              fake_images_predictions)\n",
        "    # sum the errors of the real and fake images\n",
        "    return real_loss + fake_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-wKqUWEKJtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating the generator net:\n",
        "# given a set of fake images it produced, that we then gave to the \n",
        "# discriminator, a perfect generator should have created images in a way that\n",
        "# all were classified as reals\n",
        "# So the \"error\" of the generator, is how different the fake images have been \n",
        "# classified by the discriminator, in comparisson to all 1s (all \"real\")\n",
        "\n",
        "def generator_loss(fake_images_predictions):\n",
        "    # entropy between values predicted for fake images, and all 1s\n",
        "    return cross_entropy(tf.ones_like(fake_images_predictions), \n",
        "                         fake_images_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz44ZXydKNHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# both nets will use gradient descent to train their weights, here we create \n",
        "# their GD optimizers (Adam variant) with a learning rate of 0.001\n",
        "\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0003)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2X_duUnizlw",
        "colab_type": "text"
      },
      "source": [
        "# **Traning logic**\n",
        "\n",
        "And now we define the general training logic.\n",
        "\n",
        "The training will be done in steps. At each step, we take a batch of real images, and generate another batch of fake images using the generator network.\n",
        "\n",
        "We then give the two batches to the discriminator network, and measure the losses for both networks.\n",
        "After this, we tell the networks to learn from their errors (using the adam optimizers).\n",
        "\n",
        "And finally at each step, we also generage a batch of fake images using always the same random noise, so we can visualize how the learning evolves, how the same random nose input is creating better and better images on each training step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPH00I9kKXek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    \"\"\"\n",
        "    A training step, using a batch of real images.\n",
        "    \"\"\"\n",
        "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
        "\n",
        "    with tf.GradientTape() as generator_tape,\\\n",
        "         tf.GradientTape() as discriminator_tape:\n",
        "        # generate a batck of fake images too\n",
        "        fake_images = generator(noise, training=True)\n",
        "\n",
        "        # ask the discriminator to analyze both sets of images\n",
        "        real_images_predictions = discriminator(real_images, training=True)\n",
        "        fake_images_predictions = discriminator(fake_images, training=True)\n",
        "\n",
        "        # calculate the error of both networks\n",
        "        current_discriminator_loss = discriminator_loss(\n",
        "            real_images_predictions, fake_images_predictions\n",
        "        )\n",
        "        current_generator_loss = generator_loss(fake_images_predictions)\n",
        "\n",
        "    # calculate the changes needed for both networks to get better\n",
        "    generator_gradients = generator_tape.gradient(\n",
        "        current_generator_loss, generator.trainable_variables\n",
        "    )\n",
        "    discriminator_gradients = discriminator_tape.gradient(\n",
        "        current_discriminator_loss, discriminator.trainable_variables\n",
        "    )\n",
        "\n",
        "    # apply the changes, so they become better at their tasks\n",
        "    generator_optimizer.apply_gradients(\n",
        "        zip(generator_gradients, generator.trainable_variables)\n",
        "    )\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "        zip(discriminator_gradients, discriminator.trainable_variables)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeSDTCOhKido",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs, evolution_noise=None):\n",
        "    \"\"\"\n",
        "    Train both models at the same time! Execute the train_step function a number\n",
        "    of epochs, plus generate the sample images at each epoch.\n",
        "    If evolution_noise is specified, that same noise is used to generate images\n",
        "    on each epoch.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        # go through the whole dataset in batches, learning at each batch of\n",
        "        # images\n",
        "        for real_images_batch in dataset:\n",
        "            train_step(real_images_batch)\n",
        "\n",
        "        # generate the visualization images\n",
        "        if evolution_noise is None:\n",
        "            noise = tf.random.normal([9, 100])\n",
        "        else:\n",
        "            noise = evolution_noise\n",
        "        generated_images = generator(noise, training=False)\n",
        "        show_images_grid(generated_images, fig_size=6,\n",
        "                         file_name='./evolution/{}.png'.format(start))\n",
        "\n",
        "        print('Epoch', epoch + 1,\n",
        "              'finished in', time.time() - start, \n",
        "              'seconds')\n",
        "        \n",
        "        # clear the notebook output\n",
        "        display.clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX2tapIbrx9-",
        "colab_type": "text"
      },
      "source": [
        "# **Now... train!!**\n",
        "\n",
        "Finally, we can put the networks to work and learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9KGrs_szEDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./evolution -p\n",
        "!rm ./evolution/*.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj5NDU-aSi4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(real_images_dataset, 1500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq3WT74SsY1P",
        "colab_type": "text"
      },
      "source": [
        "# **Test the trained networks**\n",
        "\n",
        "Now that we have both networks trained, test them by generating images and classifying them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NN0TKCdjSKkS",
        "colab": {}
      },
      "source": [
        "# lets test the trained generator!\n",
        "# give random noise to the generator, and see what image it produces!\n",
        "\n",
        "noise = tf.random.normal([9, 100])\n",
        "generated_images = generator(noise, training=False)\n",
        "show_images_grid(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHdfO1mSRgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets test the trained discriminator!\n",
        "# give it a few fake images, and see what it says about them\n",
        "\n",
        "discriminator(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s4t_LdvScS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and give it a few real images, and see what it says about them\n",
        "\n",
        "discriminator(sample(processed_real_images, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kjQA_FXO8Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}